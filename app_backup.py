from flask import Flask, render_template, request, jsonify, redirect, url_for, flash, send_from_directory
from werkzeug.utils import secure_filename
import sqlite3
import os
import json
from datetime import datetime, timedelta
import re
import PyPDF2
from bs4 import BeautifulSoup
from dateutil import parser as date_parser
import pandas as pd
import numpy as np
import jieba
from wordcloud import WordCloud
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import seaborn as sns
import base64
from io import BytesIO

app = Flask(__name__)
app.secret_key = 'your-secret-key-here'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# æ•°æ®åº“åˆå§‹åŒ–å’Œè¿ç§?
def init_db():
    conn = sqlite3.connect('wechat_analysis.db')
    cursor = conn.cursor()
    
    # åˆ›å»ºä¸Šä¼ è®°å½•è¡?
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS upload_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            filename TEXT NOT NULL,
            file_type TEXT NOT NULL,
            upload_time TEXT NOT NULL,
            message_count INTEGER DEFAULT 0,
            status TEXT DEFAULT 'processed'
        )
    ''')
    
    # æ£€æŸ¥messagesè¡¨æ˜¯å¦å­˜åœ?
    cursor.execute('''
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='messages'
    ''')
    
    messages_table_exists = cursor.fetchone()
    
    if messages_table_exists:
        # æ£€æŸ¥æ˜¯å¦æœ‰upload_idåˆ?
        cursor.execute('PRAGMA table_info(messages)')
        columns = cursor.fetchall()
        column_names = [col[1] for col in columns]
        
        if 'upload_id' not in column_names:
            # æ·»åŠ upload_idåˆ?
            cursor.execute('ALTER TABLE messages ADD COLUMN upload_id INTEGER')
            print("å·²æ·»åŠ upload_idåˆ—åˆ°messagesè¡?)
        
        if 'sender_type' not in column_names:
            # æ·»åŠ sender_typeåˆ?
            cursor.execute('ALTER TABLE messages ADD COLUMN sender_type TEXT DEFAULT "unknown"')
            print("å·²æ·»åŠ sender_typeåˆ—åˆ°messagesè¡?)
            
        if 'msg_type' not in column_names:
            # æ·»åŠ msg_typeåˆ?
            cursor.execute('ALTER TABLE messages ADD COLUMN msg_type TEXT DEFAULT "text"')
            print("å·²æ·»åŠ msg_typeåˆ—åˆ°messagesè¡?)
    else:
        # åˆ›å»ºæ–°çš„messagesè¡?
        cursor.execute('''
            CREATE TABLE messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                upload_id INTEGER,
                sender TEXT NOT NULL,
                sender_type TEXT NOT NULL,
                content TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                msg_type TEXT DEFAULT 'text',
                FOREIGN KEY (upload_id) REFERENCES upload_history (id)
            )
        ''')
        print("å·²åˆ›å»ºæ–°çš„messagesè¡?)
    
    conn.commit()
    conn.close()

# å…è®¸çš„æ–‡ä»¶æ‰©å±•å
ALLOWED_EXTENSIONS = {'txt', 'pdf', 'html', 'htm'}

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# æ–‡æœ¬è§£æå‡½æ•°
def parse_text_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    return extract_messages(content)

# PDFè§£æå‡½æ•°
def parse_pdf_file(file_path):
    messages = []
    with open(file_path, 'rb') as f:
        pdf_reader = PyPDF2.PdfReader(f)
        content = ""
        for page in pdf_reader.pages:
"
        messages = extract_messages(content)
    return messages

# HTMLè§£æå‡½æ•°
def parse_html_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    soup = BeautifulSoup(content, 'html.parser')
    text_content = soup.get_text()
    return extract_messages(text_content)

# æ¶ˆæ¯æå–å’Œè¯´è¯è€…è¯†åˆ?
def extract_messages(content):
    messages = []
    lines = content.strip().split('\n')
    
    # å¸¸è§çš„æ—¶é—´æˆ³æ¨¡å¼
    timestamp_patterns = [
        r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',
        r'(\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2})',
        r'(\d{2}-\d{2}-\d{4}\s+\d{2}:\d{2})',
        r'(\d{2}:\d{2})',
        r'(\d{4}/\d{2}/\d{2}\s+\d{2}:\d{2})'
    ]
    
    # è¯´è¯è€…å…³é”®è¯
    operator_keywords = ['å®¢æœ', 'é”€å”?, 'åº—å‘˜', 'é¡¾é—®', 'assistant', 'sales', 'operator', 'staff', 'å½©å¦†é¡¾é—®']
    customer_keywords = ['å®¢æˆ·', 'é¡¾å®¢', 'ç”¨æˆ·', 'customer', 'user', 'buyer']
    
    # æå–å®¢æˆ·åç§°çš„æ¨¡å¼?
    customer_name_patterns = [
        r'(\w+å°å§)ï¼?,
        r'(\w+å¥³å£«)ï¼?,
        r'(\w+å…ˆç”Ÿ)ï¼?,
        r'(\w+æ€?ï¼?,
        r'(å°\w+)ï¼?,
        r'(è€\w+)ï¼?,
        r'(\w+ç»ç†)ï¼?,
        r'(\w+ä¸»ä»»)ï¼?,
        r'(\w+)ï¼?  # é€šç”¨æ¨¡å¼ï¼Œæ”¾åœ¨æœ€å?
    ]
    
    current_message = {}
    current_customer = None  # å½“å‰è¿½è¸ªçš„å®¢æˆ?
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # å°è¯•åŒ¹é…æ—¶é—´æˆ?
        timestamp = None
        for pattern in timestamp_patterns:
            match = re.search(pattern, line)
            if match:
                timestamp = match.group(1)
                # ä¿å­˜å‰ä¸€æ¡æ¶ˆæ?
                if current_message:
                    messages.append(current_message)
                # å¼€å§‹æ–°æ¶ˆæ¯
                remaining_text = line.replace(timestamp, '').strip()
                current_message = {
                    'timestamp': timestamp,
                    'content': remaining_text,
                    'sender': 'Unknown',
                    'sender_type': 'unknown'
                }
                break
        
        if timestamp is not None and current_message:
            # æœ‰æ—¶é—´æˆ³çš„æ¶ˆæ¯ï¼Œéœ€è¦è¯†åˆ«è¯´è¯è€?
            content = current_message['content']
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ“ä½œäººå‘˜
            for keyword in operator_keywords:
                if keyword in content:
                    current_message['sender'] = content.split('ï¼?)[0] if 'ï¼? in content else 'Operator'
                    current_message['sender_type'] = 'operator'
                    break
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å®¢æˆ·ï¼Œå°è¯•æå–å®¢æˆ·åç§?
                for pattern in customer_name_patterns:
                    match = re.search(pattern, content)
                    if match:
                        customer_name = match.group(1)
                        current_message['sender'] = customer_name
                        current_message['sender_type'] = 'customer'
                        current_customer = customer_name  # æ›´æ–°å½“å‰å®¢æˆ·
                        break
                else:
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šæ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å®¢æˆ·å…³é”®è¯
                    for keyword in customer_keywords:
                        if keyword in content:
                            current_message['sender'] = current_customer or 'Customer'
                            current_message['sender_type'] = 'customer'
                            break
        
        elif timestamp is None and current_message:
            # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ä½†æœ‰å½“å‰æ¶ˆæ¯ï¼Œå¯èƒ½æ˜¯å¤šè¡Œæ¶ˆæ?
            current_message['content'] += ' ' + line
        elif timestamp is None:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å®¢æˆ·æ ‡è®°è¡Œï¼ˆå¦?å®¢æˆ·1: æå°å§?ï¼?
            customer_marker_match = re.match(r'å®¢æˆ·\d+: (.+)', line)
            if customer_marker_match:
                current_customer = customer_marker_match.group(1)
            elif ':' in line and not any(keyword in line for keyword in operator_keywords):
                # å¯èƒ½æ˜¯å®¢æˆ·è¯´è¯ä½†æ²¡æœ‰æ—¶é—´æˆ?
                current_message = {
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'content': line,
                    'sender': line.split('ï¼?)[0] if 'ï¼? in line else current_customer or 'Customer',
                    'sender_type': 'customer'
                }
    
    # ä¿å­˜æœ€åä¸€æ¡æ¶ˆæ?
    if current_message:
        messages.append(current_message)
    
    # æ—¶é—´æˆ³æ ‡å‡†åŒ–
    for message in messages:
        try:
            parsed_time = date_parser.parse(message['timestamp'])
            message['timestamp'] = parsed_time.strftime('%Y-%m-%d %H:%M:%S')
        except:
            try:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ·»åŠ å½“å‰æ—¥æœ?
                if ':' in message['timestamp']:
                    time_part = message['timestamp']
                    current_date = datetime.now().strftime('%Y-%m-%d')
                    full_timestamp = f"{current_date} {time_part}"
                    parsed_time = date_parser.parse(full_timestamp)
                    message['timestamp'] = parsed_time.strftime('%Y-%m-%d %H:%M:%S')
            except:
                message['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    return messages

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/data_import')
def data_import():
    return render_template('data_import.html')

@app.route('/dashboard')
def dashboard():
    return render_template('dashboard.html')

@app.route('/table')
def table():
    return render_template('table.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'files' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    files = request.files.getlist('files')
    upload_results = []
    
    for file in files:
        if file.filename == '':
            continue
            
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(file_path)
            
            # è§£ææ–‡ä»¶
            file_ext = filename.rsplit('.', 1)[1].lower()
            messages = []
            
            try:
                if file_ext == 'txt':
                    messages = parse_text_file(file_path)
                elif file_ext == 'pdf':
                    messages = parse_pdf_file(file_path)
                elif file_ext in ['html', 'htm']:
                    messages = parse_html_file(file_path)
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                conn = sqlite3.connect('wechat_analysis.db')
                cursor = conn.cursor()
                
                # æ’å…¥ä¸Šä¼ è®°å½•
                cursor.execute('''
                    INSERT INTO upload_history (filename, file_type, upload_time, message_count)
                    VALUES (?, ?, ?, ?)
                ''', (filename, file_ext, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), len(messages)))
                
                upload_id = cursor.lastrowid
                
                # æ’å…¥æ¶ˆæ¯è®°å½•
                for msg in messages:
                    cursor.execute('''
                        INSERT INTO messages (upload_id, sender, sender_type, content, timestamp, msg_type)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (upload_id, msg['sender'], msg['sender_type'], msg['content'], msg['timestamp'], 'text'))
                
                conn.commit()
                conn.close()
                
                upload_results.append({
                    'filename': filename,
                    'status': 'success',
                    'message_count': len(messages)
                })
                
            except Exception as e:
                upload_results.append({
                    'filename': filename,
                    'status': 'error',
                    'error': str(e)
                })
    
    return jsonify({'results': upload_results})

@app.route('/upload_history')
def get_upload_history():
    conn = sqlite3.connect('wechat_analysis.db')
    cursor = conn.cursor()
    cursor.execute('SELECT * FROM upload_history ORDER BY upload_time DESC')
    history = cursor.fetchall()
    conn.close()
    
    return jsonify([{
        'id': row[0],
        'filename': row[1],
        'file_type': row[2],
        'upload_time': row[3],
        'message_count': row[4],
        'status': row[5]
    } for row in history])

@app.route('/delete_upload/<int:upload_id>', methods=['DELETE'])
def delete_upload(upload_id):
    conn = sqlite3.connect('wechat_analysis.db')
    cursor = conn.cursor()
    
    # å…ˆåˆ é™¤ç›¸å…³çš„æ¶ˆæ¯è®°å½•
    cursor.execute('DELETE FROM messages WHERE upload_id = ?', (upload_id,))
    # å†åˆ é™¤ä¸Šä¼ è®°å½?
    cursor.execute('DELETE FROM upload_history WHERE id = ?', (upload_id,))
    
    conn.commit()
    conn.close()
    
    return jsonify({'status': 'success'})

@app.route('/api/customer_overview')
def customer_overview():
    conn = sqlite3.connect('wechat_analysis.db')
    df = pd.read_sql_query('''
        SELECT DISTINCT 
            CASE 
                WHEN sender_type = 'customer' THEN sender
                ELSE 'Unknown Customer'
            END as customer_name,
            COUNT(DISTINCT DATE(timestamp)) as chat_days,
            COUNT(*) as total_messages,
            SUM(CASE 
                WHEN content LIKE '%è½¬è´¦%' OR content LIKE '%æ”¯ä»˜%' OR content LIKE '%è´­ä¹°%' OR content LIKE '%ä»˜æ¬¾%' 
                THEN CAST(REPLACE(REPLACE(REPLACE(content, 'å…?, ''), 'ï¿?, ''), 'Â¥', '') AS REAL)
                ELSE 0
            END) as transfer_amount
        FROM messages 
        WHERE sender_type = 'customer'
        GROUP BY customer_name
    ''', conn)
    conn.close()
    
    return jsonify(df.to_dict('records'))

@app.route('/api/chat_heatmap')
def chat_heatmap():
    customer_name = request.args.get('customer')
    
    conn = sqlite3.connect('wechat_analysis.db')
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_clause = "WHERE sender_type = 'customer'"
    if customer_name and customer_name != 'all':
        where_clause += f" AND sender = '{customer_name}'"
    
    df = pd.read_sql_query(f'''
        SELECT 
            DATE(timestamp) as date,
            COUNT(*) as message_count
        FROM messages 
        {where_clause}
        GROUP BY DATE(timestamp)
        ORDER BY date
    ''', conn)
    conn.close()
    
    if not df.empty:
        df['date'] = pd.to_datetime(df['date'])
        
        # è·å–æœ€æ–°çš„æœˆä»½æ•°æ®
        latest_date = df['date'].max()
        year = latest_date.year
        month = latest_date.month
        
        # åˆ›å»ºå½“æœˆçš„å®Œæ•´æ—¥å?
        import calendar
        cal = calendar.monthcalendar(year, month)
        
        # åˆ›å»ºæ¶ˆæ¯è®¡æ•°å­—å…¸
        message_counts = {}
        for _, row in df.iterrows():
            if row['date'].year == year and row['date'].month == month:
                message_counts[row['date'].day] = row['message_count']
        
        # æ„å»ºå‘¨æ•°æ?
        weeks_data = []
        for week in cal:
            week_data = []
            for day in week:
                if day == 0:  # ä¸å±äºå½“æœˆçš„æ—¥æœŸ
                    week_data.append({'day': None, 'count': 0})
                else:
                    week_data.append({
                        'day': day, 
                        'count': message_counts.get(day, 0),
                        'date': f"{year}-{month:02d}-{day:02d}"
                    })
            weeks_data.append(week_data)
        
        return jsonify({
            'year': year,
            'month': month,
            'month_name': calendar.month_name[month],
            'weeks': weeks_data
        })
    else:
        return jsonify({})

@app.route('/api/time_distribution')
def time_distribution():
    customer_name = request.args.get('customer')
    
    conn = sqlite3.connect('wechat_analysis.db')
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_clause = "WHERE sender_type = 'customer'"
    if customer_name and customer_name != 'all':
        where_clause += f" AND sender = '{customer_name}'"
    
    df = pd.read_sql_query(f'''
        SELECT 
            CAST(strftime('%H', timestamp) AS INTEGER) as hour,
            COUNT(*) as message_count
        FROM messages 
        {where_clause}
        GROUP BY hour
        ORDER BY hour
    ''', conn)
    conn.close()
    
    # å¡«å……0-23å°æ—¶çš„å®Œæ•´æ•°æ?
    hours = list(range(24))
    df_full = pd.DataFrame({'hour': hours})
    df_result = df_full.merge(df, on='hour', how='left').fillna(0)
    
    return jsonify({
        'hours': df_result['hour'].tolist(),
        'message_counts': df_result['message_count'].astype(int).tolist()
    })

@app.route('/api/purchase_ratio')
def purchase_ratio():
    try:
        customer_name = request.args.get('customer')
        conn = sqlite3.connect('wechat_analysis.db')
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        where_clause = "WHERE sender_type = 'customer'"
        if customer_name and customer_name != 'all':
            where_clause += f" AND sender = '{customer_name}'"
        
        # æŒ‰å¤©åˆ†ç»„ï¼Œæ£€æŸ¥æ¯å¤©æ˜¯å¦æœ‰è½¬è´¦è®°å½•
        df = pd.read_sql_query(f'''
            SELECT 
                DATE(timestamp) as chat_date,
                COUNT(*) as total_messages,
                MAX(CASE 
                    WHEN content LIKE '%è½¬è´¦%' OR content LIKE '%æ”¯ä»˜%' OR content LIKE '%ä»˜æ¬¾%' OR 
                         content LIKE '%å‘çº¢åŒ?' OR content LIKE '%å¾®ä¿¡è½¬è´¦%' OR
                         content LIKE '%ï¿?' OR content LIKE '%Â¥%' 
                    THEN 1
                    ELSE 0
                END) as has_transfer
            FROM messages 
            {where_clause}
            GROUP BY DATE(timestamp)
            ORDER BY chat_date
        ''', conn)
        conn.close()
        
        print(f"è´­ä¹°æ¯”ä¾‹ç»Ÿè®¡ - åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
        
        if df.empty:
            print("æ²¡æœ‰èŠå¤©æ•°æ®")
            return jsonify({'labels': ['æš‚æ— èŠå¤©æ•°æ®'], 'values': [0]})
        
        # åˆ†ç±»ç»Ÿè®¡ï¼šæœ‰è½¬è´¦çš„å¤©æ•?vs æ— è½¬è´¦çš„å¤©æ•°
        purchase_days = df[df['has_transfer'] > 0]['total_messages'].sum()
        non_purchase_days = df[df['has_transfer'] == 0]['total_messages'].sum()
        
        print(f"æœ‰è½¬è´¦å¤©æ¶ˆæ¯æ•? {purchase_days}, æ— è½¬è´¦å¤©æ¶ˆæ¯æ•? {non_purchase_days}")
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•æœ‰è½¬è´¦çš„å¤?
        if purchase_days == 0 and non_purchase_days > 0:
            return jsonify({
                'labels': ['Non-Purchase Days'],
                'values': [non_purchase_days]
            })
        
        # å¦‚æœåªå­˜åœ¨æœ‰è½¬è´¦çš„å¤©
        if non_purchase_days == 0 and purchase_days > 0:
            return jsonify({
                'labels': ['Purchase Days'],
                'values': [purchase_days]
            })
        
        # å¦‚æœéƒ½æ²¡æœ‰æ•°æ?
        if purchase_days == 0 and non_purchase_days == 0:
            return jsonify({'labels': ['æš‚æ— æ•°æ®'], 'values': [0]})
        
        return jsonify({
            'labels': ['Purchase Days', 'Non-Purchase Days'],
            'values': [purchase_days, non_purchase_days]
        })
        
    except Exception as e:
        print(f"è´­ä¹°æ¯”ä¾‹APIé”™è¯¯: {e}")
        return jsonify({'labels': ['åŠ è½½å¤±è´¥'], 'values': [0]})

@app.route('/api/wordcloud')
def wordcloud():
    customer_name = request.args.get('customer')
    
    conn = sqlite3.connect('wechat_analysis.db')
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_clause = "WHERE sender_type = 'customer'"
    if customer_name and customer_name != 'all':
        where_clause += f" AND sender = '{customer_name}'"
    
    df = pd.read_sql_query(f'''
        SELECT content FROM messages {where_clause}
    ''', conn)
    conn.close()
    
    if df.empty:
        return jsonify({'wordcloud': '', 'words': []})
    
    # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯å†…å®?
    all_text = ' '.join(df['content'].tolist())
    
    # ä½¿ç”¨jiebaåˆ†è¯ï¼Œæ·»åŠ æ›´å¤šæ¨¡å¼?
    jieba.initialize()  # ç¡®ä¿jiebaåˆå§‹åŒ?
    words = jieba.lcut(all_text, cut_all=False)  # ç²¾ç¡®æ¨¡å¼
    
    # æ‰©å±•åœç”¨è¯åˆ—è¡?
    stop_words = {
        'çš?, 'äº?, 'æˆ?, 'ä½?, 'æ˜?, 'åœ?, 'æœ?, 'å’?, 'å°?, 'ä¸?, 'äº?, 'éƒ?, 'ä¸€', 'ä¸€ä¸?, 'ä¸?, 'ä¹?, 'å¾?, 'åˆ?, 'è¯?, 'è¦?, 'å?, 
        'ä»?, 'å¥?, 'å®?, 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'è¿?, 'é‚?, 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹?, 'æ€ä¹ˆ', 'ä¸ºä»€ä¹?, 'å?, 'å‘?, 'å•?, 'å?, 
        'å“?, 'å‘µå‘µ', 'è°¢è°¢', 'ä½ å¥½', 'å†è§', 'å¥½çš„', 'å¯ä»¥', 'æ˜¯çš„', 'ä¸æ˜¯', 'æ²¡æœ‰', 'è¿˜æœ‰', 'ç„¶å', 'æˆ–è€?, 'å¦‚æœ', 'å› ä¸º', 
        'æ‰€ä»?, 'ä½†æ˜¯', 'è€Œä¸”', 'ç°åœ¨', 'æ—¶å€?, 'åœ°æ–¹', 'ä¸œè¥¿', 'é—®é¢˜', 'åŠæ³•', 'çŸ¥é“', 'è§‰å¾—', 'æƒ³è¦', 'éœ€è¦?, 'å¯èƒ½', 
        'åº”è¯¥', 'èƒ½å¤Ÿ', 'è¿˜æ˜¯', 'æˆ–è€?, 'æˆ–è€?, 'å·²ç»', 'è¿˜æ˜¯', 'ç»?, 'å¯?, 'å?, 'å?, 'å‘?, 'å•?, 'å“?, 'å—?, 'å¥½çš„',
        'å®¢æœ', 'é”€å”?, 'åº—å‘˜', 'é¡¾å®¢', 'ç”¨æˆ·', 'äº§å“', 'æ–‡ä»¶', 'è®°å½•'
    }
    
    # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯ï¼Œåªä¿ç•™ä¸­æ–‡è¯æ±‡
    filtered_words = []
    for word in words:
        word = word.strip()
        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­æ–‡è¯æ±‡
        if (len(word) >= 2 and 
            word not in stop_words and 
            word.isalpha() and 
            any('\u4e00' <= char <= '\u9fff' for char in word)):  # åŒ…å«ä¸­æ–‡å­—ç¬¦
            filtered_words.append(word)
    
    # ç»Ÿè®¡è¯é¢‘ï¼Œè¿‡æ»¤ä½é¢‘è¯
    word_freq = {}
    for word in filtered_words:
        word_freq[word] = word_freq.get(word, 0) + 1
    
    # åªä¿ç•™å‡ºç?æ¬¡ä»¥ä¸Šçš„è¯?
    word_freq = {word: count for word, count in word_freq.items() if count >= 2}
    
    # è·å–å‰?0ä¸ªé«˜é¢‘è¯
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]
    
    # ç”Ÿæˆè¯äº‘å›?
    if word_freq:
        # å°è¯•æ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“
        font_path = None
        font_candidates = [
            'C:/Windows/Fonts/simhei.ttf',      # é»‘ä½“
            'C:/Windows/Fonts/msyh.ttc',        # å¾®è½¯é›…é»‘
            'C:/Windows/Fonts/simsun.ttc',      # å®‹ä½“
            'C:/Windows/Fonts/STXIHEI.TTF',    # åæ–‡ç»†é»‘
            'arial.ttf',                         # Arial å¤‡ç”¨
        ]
        
        for font in font_candidates:
            if os.path.exists(font):
                font_path = font
                print(f"ä½¿ç”¨å­—ä½“: {font}")
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å­—ä½“ï¼Œè¿”å›ç®€åŒ–ç‰ˆæœ?
        if not font_path:
            print("æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œè¿”å›è¯é¢‘æ•°æ®")
            return jsonify({
                'wordcloud': '',
                'words': [{'word': word, 'count': count} for word, count in top_words[:10]]
            })
        
        wc = WordCloud(
            width=800, 
            height=400, 
            background_color='white',
            font_path=font_path,
            max_words=30,
            min_font_size=12,
            max_font_size=50,
            relative_scaling=0.5,
            random_state=42,
            collocations=False,  # ä¸ä½¿ç”¨è¯è¯­æ­é…?
            colormap='tab10'  # ä½¿ç”¨å½©è‰²è°ƒè‰²æ?
        )
        
        try:
            wordcloud_img = wc.generate_from_frequencies(word_freq)
            
            # è½¬æ¢ä¸ºbase64
            buffer = BytesIO()
            wordcloud_img.to_image().save(buffer, format='PNG')
            image_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            print(f"è¯äº‘å›¾ç”ŸæˆæˆåŠŸï¼Œå‰?ä¸ªè¯: {list(word_freq.keys())[:5]}")
            
            return jsonify({
                'wordcloud': f'data:image/png;base64,{image_base64}',
                'words': [{'word': word, 'count': count} for word, count in top_words]
            })
        except Exception as e:
            print(f"è¯äº‘å›¾ç”Ÿæˆå¤±è´? {e}")
            # è¿”å›è¯é¢‘æ•°æ®ä½œä¸ºå¤‡ç”¨
            return jsonify({
                'wordcloud': '',
                'words': [{'word': word, 'count': count} for word, count in top_words[:10]]
            })
    else:
        return jsonify({'wordcloud': '', 'words': []})

# ä¸­å›½æ³•å®šèŠ‚å‡æ—?
def get_chinese_holidays(year):
    # ç®€åŒ–çš„ä¸­å›½æ³•å®šèŠ‚å‡æ—¥åˆ—è¡?
    holidays = {
        f"{year}-01-01": "å…ƒæ—¦",
        f"{year}-02-10": "æ˜¥èŠ‚", f"{year}-02-11": "æ˜¥èŠ‚", f"{year}-02-12": "æ˜¥èŠ‚",
        f"{year}-04-05": "æ¸…æ˜èŠ?,
        f"{year}-05-01": "åŠ³åŠ¨èŠ?,
        f"{year}-06-22": "ç«¯åˆèŠ?,
        f"{year}-09-29": "ä¸­ç§‹èŠ?, f"{year}-09-30": "ä¸­ç§‹èŠ?,
        f"{year}-10-01": "å›½åº†èŠ?, f"{year}-10-02": "å›½åº†èŠ?, f"{year}-10-03": "å›½åº†èŠ?
    }
    return holidays

# æ£€æŸ¥æ˜¯å¦ä¸ºå‘¨æœ«
def is_weekend(date_str):
    date_obj = pd.to_datetime(date_str).date()
    return date_obj.weekday() >= 5  # 5=å‘¨å…­, 6=å‘¨æ—¥

# æ£€æŸ¥æ˜¯å¦ä¸ºèŠ‚å‡æ—?
def is_holiday_or_nearby(date_str, holidays, days_range=2):
    date_obj = pd.to_datetime(date_str).date()
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯èŠ‚å‡æ—?
    if date_str in holidays:
        return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨èŠ‚å‡æ—¥é™„è¿‘ï¼ˆå‰åå‡ å¤©ï¼?
    for holiday_date in holidays.keys():
        holiday_obj = pd.to_datetime(holiday_date).date()
        if abs((date_obj - holiday_obj).days) <= days_range:
            return True
    
    return False

# æ£€æŸ¥æ˜¯å¦ä¸ºä¿ƒé”€æ—¥é™„è¿?
def is_promotion_nearby(date_str):
    date_obj = pd.to_datetime(date_str).date()
    # æ£€æŸ?18é™„è¿‘
    june_18 = datetime(date_obj.year, 6, 18).date()
    if abs((date_obj - june_18).days) <= 3:  # å‰å3å¤?
        return True
    
    # æ£€æŸ¥åŒ11é™„è¿‘
    nov_11 = datetime(date_obj.year, 11, 11).date()
    if abs((date_obj - nov_11).days) <= 3:  # å‰å3å¤?
        return True
    
    return False

# æ£€æŸ¥æ˜¯å¦ä¸ºèŠ‚æ—¥é™„è¿‘
def is_festival_nearby(date_str):
    date_obj = pd.to_datetime(date_str).date()
    festivals = [
        (2, 14, "æƒ…äººèŠ?),    # 2æœ?4æ—?
        (3, 8, "ä¸‰å…«èŠ?),     # 3æœ?æ—?
        (5, 20, "520"),       # 5æœ?0æ—?
        (12, 25, "åœ£è¯èŠ?)     # 12æœ?5æ—?
    ]
    
    for month, day, name in festivals:
        festival_date = datetime(date_obj.year, month, day).date()
        if abs((date_obj - festival_date).days) <= 3:  # å‰å3å¤?
            return True
    
    return False

@app.route('/api/customer_labels')
def customer_labels():
    try:
        conn = sqlite3.connect('wechat_analysis.db')
        
        # è·å–æ‰€æœ‰å®¢æˆ·æ¶ˆæ¯æ•°æ?
        df = pd.read_sql_query('''
            SELECT 
                CASE 
                    WHEN sender_type = 'customer' THEN sender
                    ELSE 'Unknown Customer'
                END as customer_name,
                DATE(timestamp) as chat_date,
                timestamp,
                strftime('%H', timestamp) as hour,
                content,
                CASE 
                    WHEN content LIKE '%è½¬è´¦%' OR content LIKE '%æ”¯ä»˜%' OR content LIKE '%ä»˜æ¬¾%' OR 
                         content LIKE '%å‘çº¢åŒ?' OR content LIKE '%å¾®ä¿¡è½¬è´¦%' OR
                         content LIKE '%ï¿?' OR content LIKE '%Â¥%' 
                    THEN 1
                    ELSE 0
                END as has_transfer,
                CASE 
                    WHEN content LIKE '%å¥½è¯„%' OR content LIKE '%æ»¡æ„%' OR content LIKE '%ä¸é”™%' OR
                         content LIKE '%å¾ˆå¥½%' OR content LIKE '%æ¨è%' OR content LIKE '%è´¨é‡å¥?' OR
                         content LIKE '%æœåŠ¡å¥?' OR content LIKE '%å†æ¬¡è´­ä¹°%' OR content LIKE '%å›è´­%'
                    THEN 1
                    ELSE 0
                END as has_positive_feedback,
                CASE 
                    WHEN content LIKE '%æ”¶åˆ°è´?' OR content LIKE '%æ”¶åˆ°äº?' OR content LIKE '%å·²ç»æ”¶åˆ°%' OR
                         content LIKE '%å¿«é€’åˆ°äº?' OR content LIKE '%å·²ç­¾æ”?' OR content LIKE '%åˆ°è´§äº?'
                    THEN 1
                    ELSE 0
                END as has_received_goods
            FROM messages 
            WHERE sender_type = 'customer'
            ORDER BY chat_date, timestamp
        ''', conn)
        conn.close()
        
        if df.empty:
            return jsonify([])
        
        labels_result = []
        
        # æŒ‰å®¢æˆ·åˆ†ç»„åˆ†æ?
        for customer, customer_data in df.groupby('customer_name'):
            # 1. Date Labels åˆ†æ
            date_labels = []
            
            # è®¡ç®—æ¯æ—¥æ¶ˆæ¯é¢‘ç‡
            daily_counts = customer_data.groupby('chat_date').size().reset_index(name='message_count')
            avg_count = daily_counts['message_count'].mean()
            
            # æ£€æŸ¥ä¿ƒé”€æ—?
            promo_days = daily_counts[daily_counts['chat_date'].apply(is_promotion_nearby)]
            if not promo_days.empty and promo_days['message_count'].mean() > avg_count * 1.5:
                date_labels.append("Promotion-oriented")
            
            # æ£€æŸ¥èŠ‚å‡æ—¥
            holidays = get_chinese_holidays(customer_data['chat_date'].iloc[0][:4])
            holiday_days = daily_counts[daily_counts['chat_date'].apply(
                lambda x: is_holiday_or_nearby(x, holidays) or is_weekend(x)
            )]
            if not holiday_days.empty and holiday_days['message_count'].mean() > avg_count * 1.5:
                date_labels.append("Holiday-oriented")
            
            # æ£€æŸ¥èŠ‚æ—?
            festival_days = daily_counts[daily_counts['chat_date'].apply(is_festival_nearby)]
            if not festival_days.empty and festival_days['message_count'].mean() > avg_count * 1.5:
                date_labels.append("Festival-oriented")
            
            # 2. Time Labels åˆ†æ
            time_labels = []
            hour_counts = customer_data.groupby('hour').size()
            total_messages = len(customer_data)
            
            # ç»Ÿè®¡å„æ—¶æ®µæ¶ˆæ¯æ•°é‡?
            daytime_messages = hour_counts.loc[hour_counts.index.astype(int).between(8, 17)].sum()
            evening_messages = hour_counts.loc[hour_counts.index.astype(int).between(18, 23)].sum()
            early_morning_messages = hour_counts.loc[hour_counts.index.astype(int).between(0, 7)].sum()
            
            if daytime_messages / total_messages >= 0.5:
                time_labels.append("Daytime")
            if evening_messages / total_messages >= 0.5:
                time_labels.append("Evening")
            if early_morning_messages / total_messages >= 0.5:
                time_labels.append("Early Morning")
            
            # 3. Behaviour Labels åˆ†æ
            behaviour_labels = []
            
            # è®¡ç®—è´­ä¹°ä¼šè¯æ•°å’Œæ€»ä¼šè¯æ•°
            chat_sessions = customer_data.groupby('chat_date').size().reset_index(name='session_messages')
            purchase_sessions = customer_data[customer_data['has_transfer'] == 1].groupby('chat_date').size().reset_index(name='purchase_sessions')
            
            total_sessions = len(chat_sessions)
            purchase_session_count = len(purchase_sessions)
            
            if total_sessions > 0:
                purchase_rate = purchase_session_count / total_sessions
                if purchase_rate < 1/20:  # å°äº5%
                    behaviour_labels.append("Hesitant Buyers")
                elif purchase_rate >= 1/20:  # å¤§äºç­‰äº5%
                    behaviour_labels.append("Quick Buyers")
            
            # 4. RFM æ ‡ç­¾åˆ†æ
            rfm_labels = calculate_rfm_labels(customer_data)
            
            # 5. Customer Lifecycle æ ‡ç­¾åˆ†æ
            lifecycle_labels = calculate_lifecycle_labels(customer_data)
            
            customer_labels = {
                'customer_name': customer,
                'basic_labels': {
                    'date_labels': date_labels,
                    'time_labels': time_labels,
                    'behaviour_labels': behaviour_labels
                },
                'analysis_labels': {
                    'rfm_labels': rfm_labels,
                    'lifecycle_labels': lifecycle_labels
                },
                'custom_labels': []  # è¿™é‡Œå¯ä»¥ä»æ•°æ®åº“è¯»å–è‡ªå®šä¹‰æ ‡ç­¾ï¼Œæš‚æ—¶ä¸ºç©º
            }
            
            labels_result.append(customer_labels)
        
        return jsonify(labels_result)
        
    except Exception as e:
        print(f"å®¢æˆ·æ ‡ç­¾APIé”™è¯¯: {e}")
        return jsonify({'error': str(e)})

def calculate_rfm_labels(customer_data):
    """
    è®¡ç®— RFM æ ‡ç­¾
    R (Recency): æœ€è¿‘è´­ä¹°æ—¶é—?
    F (Frequency): è´­ä¹°æ¬¡æ•°
    M (Monetary): æ¶ˆè´¹é‡‘é¢
    """
    try:
        # è·å–æœ‰è´­ä¹°è®°å½•çš„æ—¥æœŸ
        purchase_dates = customer_data[customer_data['has_transfer'] == 1]['chat_date'].unique()
        
        if len(purchase_dates) == 0:
            return ["No Purchase Data"]
        
        # è®¡ç®—æ¶ˆè´¹é‡‘é¢ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æå–å…·ä½“é‡‘é¢ï¼?
        total_amount = len(purchase_dates) * 100  # å‡è®¾æ¯æ¬¡æ¶ˆè´¹100å…?
        
        # R - æœ€è¿‘è´­ä¹°æ—¶é—´ï¼ˆå¤©æ•°ï¼?
        latest_purchase = pd.to_datetime(max(purchase_dates))
        current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))
        recency_days = (current_date - latest_purchase).days
        
        # F - è´­ä¹°é¢‘ç‡
        frequency = len(purchase_dates)
        
        # M - æ¶ˆè´¹é‡‘é¢
        monetary = total_amount
        
        # æ ¹æ®ä¸šåŠ¡è§„åˆ™å®šä¹‰é«˜ä½é˜ˆå€?
        r_threshold = 30  # 30å¤©å†…ä¸ºé«˜
        f_threshold = 3   # 3æ¬¡ä»¥ä¸Šä¸ºé«?
        m_threshold = 300 # 300å…ƒä»¥ä¸Šä¸ºé«?
        
        # åˆ¤æ–­é«˜ä½
        r_level = "High" if recency_days <= r_threshold else "Low"
        f_level = "High" if frequency >= f_threshold else "Low"
        m_level = "High" if monetary >= m_threshold else "Low"
        
        # æ ¹æ®RFMç»„åˆæ‰“æ ‡ç­?
        if r_level == "High" and f_level == "High" and m_level == "High":
            return ["Important Value Customers"]
        elif r_level == "High" and f_level == "Low" and m_level == "High":
            return ["Important Growth Customers"]
        elif r_level == "Low" and f_level == "High" and m_level == "High":
            return ["Important Retention Customers"]
        elif r_level == "Low" and f_level == "Low" and m_level == "High":
            return ["Important Win-Back Customers"]
        elif r_level == "High" and f_level == "High" and m_level == "Low":
            return ["General Value Customers"]
        elif r_level == "High" and f_level == "Low" and m_level == "Low":
            return ["General Growth Customers"]
        elif r_level == "Low" and f_level == "High" and m_level == "Low":
            return ["General Retention Customers"]
        else:  # r_level == "Low" and f_level == "Low" and m_level == "Low"
            return ["General Win-Back Customers"]
            
    except Exception as e:
        print(f"RFMæ ‡ç­¾è®¡ç®—é”™è¯¯: {e}")
        return ["RFM Calculation Error"]

def calculate_lifecycle_labels(customer_data):
    """
    è®¡ç®— Customer Lifecycle æ ‡ç­¾
    """
    try:
        # è·å–æ‰€æœ‰èŠå¤©æ—¥æœ?
        chat_dates = customer_data['chat_date'].unique()
        purchase_dates = customer_data[customer_data['has_transfer'] == 1]['chat_date'].unique()
        
        # ç»Ÿè®¡åé¦ˆå’Œæ”¶è´?
        has_feedback = customer_data['has_positive_feedback'].sum() > 0
        has_received = customer_data['has_received_goods'].sum() > 0
        
        total_chat_days = len(chat_dates)
        total_purchases = len(purchase_dates)
        
        # Awareness Stage: åªæœ‰ä¸€æ¬¡å¯¹è¯?
        if total_chat_days == 1:
            return ["Awareness Stage"]
        
        # Consideration Stage: å¤šæ¬¡å¯¹è¯ä½†æ²¡æœ‰ä¸‹å?
        if total_chat_days > 1 and total_purchases == 0:
            return ["Consideration Stage"]
        
        # Purchase Stage: ç¬¬ä¸€æ¬¡ä¸‹å?
        if total_purchases == 1:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ”¶è´§ä½†æœªè¯„ä»?
            if has_received and not has_feedback:
                return ["Usage Stage"]
            else:
                return ["Purchase Stage"]
        
        # Loyalty Stage: æœ‰æ­£é¢åé¦?
        if has_feedback:
            return ["Loyalty Stage"]
        
        # Advocacy Stage: ç¬¬äºŒæ¬¡ä¸‹å?
        if total_purchases >= 2:
            return ["Advocacy Stage"]
        
        # Churn Stage: è¶…è¿‡6ä¸ªæœˆæ²¡æœ‰èŠå¤©
        if len(chat_dates) > 0:
            latest_chat = pd.to_datetime(max(chat_dates))
            current_date = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))
            days_since_last_chat = (current_date - latest_chat).days
            
            if days_since_last_chat > 180:  # 6ä¸ªæœˆ
                return ["Churn Stage"]
        
        # é»˜è®¤è¿”å›æ´»è·ƒçŠ¶æ€?
        return ["Active Stage"]
        
    except Exception as e:
        print(f"Lifecycleæ ‡ç­¾è®¡ç®—é”™è¯¯: {e}")
        return ["Lifecycle Calculation Error"]

# æ·»åŠ æ ·æœ¬æ–‡ä»¶è·¯ç”±
@app.route('/samples/<filename>')
def serve_sample(filename):
    samples_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'samples')
    return send_from_directory(samples_dir, filename)

if __name__ == '__main__':
    init_db()
    app.run(debug=True, host='0.0.0.0', port=5000)
